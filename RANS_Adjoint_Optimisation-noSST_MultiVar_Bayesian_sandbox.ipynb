{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from jax.config import config \n",
    "import jax.numpy as np\n",
    "config.update('jax_enable_x64', True)\n",
    "import numpy as onp\n",
    "#import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import grad, jit, random\n",
    "from jax.ops import index, index_add, index_update\n",
    "from Mesh_fd import Mesh\n",
    "import copy\n",
    "import scipy\n",
    "import scipy.stats as ss\n",
    "from tqdm import tqdm #conda install tqdm - this is needed for plotting a progress bar\n",
    "import time\n",
    "from jax.interpreters import xla\n",
    "date = time.strftime(\"%d_%m_%Y\")\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "matplotlib.rcParams['figure.figsize'] = [8,5]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum equation (fully developed channel)\n",
    "The streamwise momentum equation of the Reynolds-averaged Navier-Stokes equations for a fully developed turbulent channel flow reads, \n",
    "\n",
    "$$ \\mu \\frac{d^2\\left<U\\right>}{dy^2} + \\frac{d}{dy}\\left(\\mu_t  \\frac{d\\left<U\\right>}{dy}\\right) = -\\frac{dP}{dx},$$ \n",
    "\n",
    "\n",
    "with $\\left<U\\right>$ the streamwise mean velocity, $\\mu$ the dynamic visocity, and $\\mu_t$ the Eddy viscosity which is obtained by a solving a turbulence model. Linear eddy visosity is used to model the Reynolds stress term here approximate by $\\mu_t  \\frac{d\\left<U\\right>}{dy}$. Wall units are used to non-dimensionalize the Navier-Stokes equations, where mean velocity and RS term is normalised by frictional velocity $v_{\\tau}$ and $y$ bu viscous length scale $\\frac{\\nu}{u_{\\tau}}$. Mean pressure gradient is given by $-\\frac{dp}{dx}=\\frac{\\tau_w}{\\delta}$ which upon normalisation with wall units gives $-1$, considering $\\delta=1$ for the channel half height defining the forcing on the right-hand-side. \n",
    "Using the product rule, the momentum equation can also be written as  \n",
    "\n",
    "$$\\frac{d\\mu_t}{dy}\\frac{d \\left<U\\right>}{dy} + (\\mu+\\mu_t)\\frac{d^2 \\left<U\\right>}{dy^2}=-1$$\n",
    "\n",
    "Now it is easy to formulate a linear system $ A u = -1 $ which can be solved using a direct linear solver.\n",
    "\n",
    "$$\\left[\\frac{d\\mu_t}{dy}\\frac{d}{dy} + (\\mu+\\mu_t)\\frac{d^2}{dy^2}\\right] \\left<U\\right>=-1 $$\n",
    "    \n",
    "\n",
    "$\\mu_t$ can also be taken as parameter to be optimised. The optimsation funtional is of the form $min_{\\mu_t}J(\\left<U\\right>(\\mu_t),\\mu_t)$, here it can be \n",
    "$$ ||\\left<U\\right>_{DNS}-\\left<U\\right>(\\mu_t)||^2 \\quad \\textrm{s.t} \\quad \\mathcal{F}(\\left<U\\right>, \\mu_t) = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for RANS solution.\n",
    "def solveRANS(mu_turb):\n",
    "\n",
    "    n    = mesh.nPoints\n",
    "    u    = np.zeros(n)          # velocity \n",
    "    \n",
    "    #mut=np.zeros(mu_turb.size+2)\n",
    "    #mut[0]=0              # Dirichlet BC\n",
    "    #index_update(mut,index[1:-1],mu_turb)\n",
    "    #mut[-1]=0\n",
    "    mut  = mu_turb       # eddy viscosity \n",
    "    #Atul: We have scalar value of density and viscoity here\n",
    "\n",
    "    \n",
    "    residual   = 1.0e20\n",
    "    iterations = 0\n",
    "    #print(mu)\n",
    "    #print(\"Start iterating\")\n",
    "\n",
    "    while residual > 1.0e-6 and iterations < 10000:\n",
    "\n",
    "     \n",
    "\n",
    "        # Solve momentum equation:  0 = d/dy[(mu+mut)dudy] - 1\n",
    "        # diffusion matrix: mueff*d2phi/dy2 + dmueff/dy dphi/dy    \n",
    "        #A =  np.einsum('i,ij->ij', mu + mut, mesh.d2dy2)\n",
    "        #A=np.multiply((mu+mut),mesh.d2dy2)    #if mu_t is scalar, uncomment and comment the bottom line.  \n",
    "        A = np.einsum('i,ij->ij', mesh.ddy@(mut), mesh.ddy) \\\n",
    "        + np.einsum('i,ij->ij', mu + mut, mesh.d2dy2)\n",
    "        # Solve \n",
    "        \n",
    "        #u_old = u.copy()\n",
    "        \n",
    "        u_old=copy.deepcopy(u)\n",
    "        #u[1:n-1]=np.linalg.solve(A[1:n-1, 1:n-1], -np.ones(n-2))\n",
    "        u=index_update(u,index[1:n-1],np.linalg.solve(A[1:n-1, 1:n-1], -np.ones(n-2)))   \n",
    "        \n",
    "        residual = np.linalg.norm(u-u_old)/n\n",
    "        \n",
    "\n",
    "        # Printing residuals\n",
    "        #if iterations%100 == 0: print(\"iteration: \",iterations, \", Residual(u) = \", residual)\n",
    "        iterations = iterations + 1\n",
    "\n",
    "    #print(\"iteration: \",iterations, \", Residual(u) = \", residual)\n",
    "    \n",
    "    return u "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh generation and inputs\n",
    "Load DNS data and call mesh file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReTau  =  395.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atul_0711/miniconda3/envs/fenicsproject/lib/python3.8/site-packages/jax/lib/xla_bridge.py:122: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import linecache\n",
    "\n",
    "# Wall clustered structured mesh\n",
    "mesh = Mesh(150, 2, 6, 1)  # mesh point, chaanel height, stretching factor, stencil\n",
    "\n",
    "DNS_case = [\"constProperty.txt\", \\\n",
    "            \"constReTauStar.txt\", \\\n",
    "            \"gasLike.txt\", \\\n",
    "            \"liquidLike.txt\"]\n",
    "file = \"DNS_data/\"+ DNS_case[1]  # chose case\n",
    "\n",
    "# get parameters from DNS or set these parameters (they must be defined)\n",
    "line = linecache.getline(file, 39)[1:].split()       \n",
    "ReTau  = float(line[0]); print(\"ReTau  = \", ReTau)   # Reynolds number\n",
    "\n",
    "# load dns data\n",
    "DNS = onp.loadtxt(file,skiprows=88)\n",
    "\n",
    "mu=1.0/ReTau  ## In the DNS data generation mu is varrying with y. For simplicity we take it to be constant\n",
    "#Extrapolate DNS u to RANS grid\n",
    "u_DNS=onp.interp(np.minimum(mesh.y, mesh.y[-1]-mesh.y) , DNS[:,0], DNS[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing initial $\\mu_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "mu_t_RANS=np.array([0.00000000e+00, 7.47051770e-09, 6.55464377e-08, 2.79792381e-07,\n",
    "       8.44475255e-07, 2.07231617e-06, 4.42491657e-06, 8.53835836e-06,\n",
    "       1.52349238e-05, 2.55083410e-05, 4.04688599e-05, 6.12399432e-05,\n",
    "       8.88142654e-05, 1.23901272e-04, 1.66819034e-04, 2.17480068e-04,\n",
    "       2.75486294e-04, 3.50195460e-04, 4.73238061e-04, 6.17266940e-04,\n",
    "       7.82504485e-04, 9.69511263e-04, 1.17921502e-03, 1.41287563e-03,\n",
    "       1.67202631e-03, 1.95841002e-03, 2.27391821e-03, 2.62053294e-03,\n",
    "       3.00027167e-03, 3.41513354e-03, 3.86704608e-03, 4.35781126e-03,\n",
    "       4.88905065e-03, 5.46214908e-03, 6.07819739e-03, 6.73793458e-03,\n",
    "       7.44169093e-03, 8.18933397e-03, 8.98022031e-03, 9.81315746e-03,\n",
    "       1.06863812e-02, 1.15975558e-02, 1.25438080e-02, 1.35218067e-02,\n",
    "       1.45278023e-02, 1.55575996e-02, 1.66065667e-02, 1.76696854e-02,\n",
    "       1.87416455e-02, 1.98169915e-02, 2.08903253e-02, 2.19565758e-02,\n",
    "       2.30113382e-02, 2.40512905e-02, 2.50746860e-02, 2.60819166e-02,\n",
    "       2.70761297e-02, 2.80638635e-02, 2.90556388e-02, 3.00664070e-02,\n",
    "       3.11157045e-02, 3.22272995e-02, 3.34280648e-02, 3.47457761e-02,\n",
    "       3.62055807e-02, 3.78250504e-02, 3.96080677e-02, 4.15383001e-02,\n",
    "       4.35735764e-02, 4.56429096e-02, 4.76479316e-02, 4.94699317e-02,\n",
    "       5.09824842e-02, 5.20680816e-02, 5.26357345e-02, 5.26357345e-02,\n",
    "       5.20680816e-02, 5.09824842e-02, 4.94699317e-02, 4.76479316e-02,\n",
    "       4.56429096e-02, 4.35735764e-02, 4.15383001e-02, 3.96080677e-02,\n",
    "       3.78250504e-02, 3.62055807e-02, 3.47457761e-02, 3.34280648e-02,\n",
    "       3.22272995e-02, 3.11157045e-02, 3.00664070e-02, 2.90556388e-02,\n",
    "       2.80638635e-02, 2.70761297e-02, 2.60819166e-02, 2.50746860e-02,\n",
    "       2.40512905e-02, 2.30113382e-02, 2.19565758e-02, 2.08903253e-02,\n",
    "       1.98169915e-02, 1.87416455e-02, 1.76696854e-02, 1.66065667e-02,\n",
    "       1.55575996e-02, 1.45278023e-02, 1.35218067e-02, 1.25438080e-02,\n",
    "       1.15975558e-02, 1.06863812e-02, 9.81315746e-03, 8.98022031e-03,\n",
    "       8.18933397e-03, 7.44169093e-03, 6.73793458e-03, 6.07819739e-03,\n",
    "       5.46214908e-03, 4.88905065e-03, 4.35781126e-03, 3.86704608e-03,\n",
    "       3.41513354e-03, 3.00027167e-03, 2.62053294e-03, 2.27391821e-03,\n",
    "       1.95841002e-03, 1.67202631e-03, 1.41287563e-03, 1.17921502e-03,\n",
    "       9.69511263e-04, 7.82504485e-04, 6.17266940e-04, 4.73238061e-04,\n",
    "       3.50195460e-04, 2.75486294e-04, 2.17480068e-04, 1.66819034e-04,\n",
    "       1.23901272e-04, 8.88142654e-05, 6.12399432e-05, 4.04688599e-05,\n",
    "       2.55083410e-05, 1.52349238e-05, 8.53835836e-06, 4.42491657e-06,\n",
    "       2.07231617e-06, 8.44475255e-07, 2.79792381e-07, 6.55464377e-08,\n",
    "       7.47051770e-09, 0.00000000e+00])\n",
    "       \n",
    "#Case 1: Starting with mu_t from RANS solution       \n",
    "noise=0 ## Internsity of noise can be controlled with changing sigma, 0 for no noise, onp.random.normal(0,0.0005,150) for noise\n",
    "mu_t=mu_t_RANS+noise\n",
    "\n",
    "'''\n",
    "#Case 2: If it is randombly choosed from a smooth parabolic function\n",
    "dim=np.size(u_DNS)\n",
    "y=np.linspace(0,2,dim)\n",
    "\n",
    "#mu_t=-(y-1)**2 +y\n",
    "mu_t=-(y-1)**2 +1\n",
    "mu_t=0.01*mu_t\n",
    "#dim=np.size(u_DNS)\n",
    "#mu_t = onp.random.normal(0.04,0.01,dim)\n",
    "##mu_t=onp.float32(mu_t)\n",
    "'''\n",
    "\n",
    "# Case 3: If its a scalar\n",
    "#mu_t=0.01\n",
    "\n",
    "plt.plot(mu_t,mesh.y)\n",
    "#plt.plot(mu_t_RANS,mesh.y)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Implementation\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior\n",
    "##zero mean gaussian\n",
    "class GaussianPrior(object):\n",
    "    \"\" #Write Desciption here\n",
    "    def __init__(self, mean, ssigma, f = None):\n",
    "\n",
    "        self._mean = mean\n",
    "        self._ssigma = ssigma  # sigma squared, i.e. variance\n",
    "        \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._mean.size\n",
    "\n",
    "    def LogEvaluate(self, x):\n",
    "\n",
    "        return -0.5*self.dim*onp.log(2*onp.pi) - 0.5*self.dim*onp.log(self._ssigma) - 0.5*(1/self._ssigma)*np.dot(x-self._mean, x-self._mean)  \n",
    "\n",
    "##Gaussian Markovian Prior\n",
    "\n",
    "class GaussianMarkPrior(object):\n",
    "    \"\" #Write Desciption here\n",
    "    def __init__(self, pres, f = None):\n",
    "\n",
    "        #self._mean = mean\n",
    "        self._pres = pres  # Q: the precision matrix\n",
    "        \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._pres.size\n",
    "    \n",
    "    def LogEvaluate(self, x):\n",
    "\n",
    "        #return -0.5*self.dim*onp.log(2*onp.pi) - 0.5*onp.log(onp.linalg.det(self._pres)) -0.5 * onp.dot(x, onp.dot(self._pres, x)) \n",
    "        return -0.5 * np.dot(x, np.dot(self._pres, x))\n",
    "class GaussianLikelihood(object):\n",
    "    \n",
    "    def __init__(self, data, model, ssigma):\n",
    "        \n",
    "        self._data = data     # vector\n",
    "        self._model = model   # callable, RANS solver\n",
    "        self._ssigma = ssigma   # variance of observation (noise)\n",
    "        \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._data.size\n",
    "        \n",
    "        \n",
    "    def LogEvaluate(self, x):\n",
    "        \n",
    "        U_RANS = self._model(x) #RANS solution\n",
    "        return -0.5*self.dim*onp.log(2*onp.pi) - 0.5*self.dim*onp.log(self._ssigma) - 0.5*(1/self._ssigma)*np.dot(self._data-U_RANS, self._data-U_RANS)\n",
    "\n",
    "class Posterior(object):\n",
    "    \n",
    "    def __init__(self, prior, likelihood):\n",
    "        \n",
    "        self._prior = prior\n",
    "        self._likelihood = likelihood\n",
    "        \n",
    "    def LogEvaluate(self, x):\n",
    "    \n",
    "        return self._prior.LogEvaluate(x) + self._likelihood.LogEvaluate(x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Markovian Prior\n",
    "\n",
    "The highly jumpy (non-smooth) parameters after optimisation elicits the need for a better prior, something which penalises the jumps in neighbouring nodes thus incorporating spatial correlations. We will use Gaussian markov random field priors \\cite{Bardsley2013}. For our current turbulent channel flow it takes the form\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mu_{t,i}|\\bm{\\mu}_{t,\\partial_{i}} \\sim \\mathcal{N}\\left(\\Bar{\\mu}_{t,\\partial_{i}},(\\delta n_i/h^2)^{-1}\\right)\n",
    "\\end{equation}\n",
    "where $\\partial_i$ is the neighbouring system (or stencil) for $i=1,\\dots,n$, $n_i=|\\partial_i|$ and $\\delta>0$ (for scaling), $\\Bar{\\mu}_{t,\\partial_{i}}=\\frac{1}{n_i}\\sum_{j \\in \\partial_i} x_j$ is the mean of neighbouring values, and the joint density function is given by \n",
    "\\begin{equation}\n",
    "   p(\\bm{\\mu}_t)=(2\\pi)^{-n/2}|\\bm{Q}|^{1/2}\\textrm{exp}\\left(\\-\\frac{1}{2}\\bm{\\mu}_t^T \\bm{Q}\\bm{\\mu}_t\\right)\n",
    "\\end{equation}\n",
    "where $\\bm{Q}$ is the precision matrix which in the case being a finite difference discretisation with Dirichlet BC with $\\bm{\\mu}_t(0)=0,\\bm{\\mu}_t(n+1)=0$ is given by\n",
    "\\begin{equation}\n",
    "    [\\bm{Q}]_{ij}=\\frac{\\delta}{h^2}\\begin{cases}\n",
    "    n_i &\\text{$i=j$},\\\\\n",
    "    -1  &\\text{$j \\in \\partial_i$},\\\\\n",
    "    o &\\text{otherwise}.\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "For our case, we consider variation in only $y$ direction so $\\partial_i=\\{i-1,i+1\\}$ for $i=1,\\dots,n$ and $n_i=2$ for all $i$ with $h=1/(n+1)$. Similarly periodic and Neumann BCs can also be incorporated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for the posterior and prior\n",
    "\n",
    "\n",
    "# Input for gaussian markovian prior\n",
    "''' constructing FD matrix with dirichlet BC, For Neumann n periodic BC, L matric will change, check paper.'''\n",
    "#Depending on FD/FE the L matrix changes. Also based uniform/non uniform grid\n",
    "n_i=2\n",
    "\n",
    "L=onp.zeros((mesh.y.size,mesh.y.size))\n",
    "for i in range(1,mesh.y.size-1):\n",
    "    for j in range(1,mesh.y.size-1):\n",
    "        if i==j:        \n",
    "            L[i,j]=n_i\n",
    "        elif i==j+1 or i==j-1:\n",
    "            L[i,j]=-1\n",
    "L[0,0]=1\n",
    "L[-1,-1]=1\n",
    "delta=0.1\n",
    "h=(max(mesh.y)-min(mesh.y))/(mesh.y.size-1)\n",
    "Q=(delta/h**2)*L\n",
    "\n",
    "#ssigma_prior=10\n",
    "ss_likelihood=8\n",
    "ss_prior=Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for the posterior and prior\n",
    "\n",
    "# Input for gaussian markovian prior\n",
    "n_i=2\n",
    "N=mesh.y.size        #total number fo point\n",
    "L=onp.zeros((N-2,N-2))\n",
    "for i in range(N-2):\n",
    "    for j in range(N-2):\n",
    "        if i==j:\n",
    "            L[i,j]=n_i\n",
    "        elif i==j+1 or i==j-1:\n",
    "            L[i,j]=-1\n",
    "delta=0.1\n",
    "h=(mesh.y[1]-mesh.y[-2])/(mesh.y.size-1)   ## no of nodes ecluding boundary nodes + 1= no of total nodes -1\n",
    "Q=(delta/h**2)*L\n",
    "\n",
    "#ssigma_prior=10\n",
    "ss_likelihood=8\n",
    "ss_prior=Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 148)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_prior.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining log_h which returns value of cuntion and the gradient\n",
    "\n",
    "# Definig Variance\n",
    "\n",
    "#ssigma_prior=10   ## this value is sigma^2\n",
    "#ssigma_likelihood=8\n",
    "\n",
    "dim_mut=np.size(mu_t)\n",
    "mean_prior=np.zeros(dim_mut)\n",
    "prior=GaussianMarkPrior(ss_prior)\n",
    "likelihood = GaussianLikelihood(u_DNS, solveRANS, ss_likelihood)\n",
    "posterior = Posterior(prior, likelihood)\n",
    "#pos_log_jit=jit(posterior.LogEvaluate)\n",
    "grad_posterior_fct=grad(posterior.LogEvaluate)   #Implementation using JAX. Can you swotched to TF.\n",
    "\n",
    "#def log_h(x,ss_prior,ss_likelihood):\n",
    "def log_h(x):\n",
    "    \"\"\"Return objective value and jacobian value wrt. x\"\"\"\n",
    "    #prior = GaussianPrior(mean_prior, ss_prior)  # zero mean gaussian\n",
    "    value_posterior=posterior.LogEvaluate(x)\n",
    "    grad_posterior=grad_posterior_fct(x)\n",
    "    return value_posterior, grad_posterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the fun\n",
    "\n",
    "val,grad_chk=log_h(mu_t[1:-1])\n",
    "plt.plot(np.arange(np.size(mu_t[1:-1])),grad_chk,'b-',label=\"JAX\")\n",
    "print('value=',val)\n",
    "#plt.savefig('Figures/grad_logPosterior'+date+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Methods (MCMC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sample from the posterior, NOTE: MALA can be implemented to account from the gradient. Grad of likelihood function needs to be passed.\n",
    "def random_walk_metropolis(N, stepsize, x0):\n",
    "    \n",
    "    x = x0  #Intial value for mut essentially/start with {0}\n",
    "    dimx = x0.size\n",
    "    logp = posterior.LogEvaluate(x0)\n",
    "    accepted = 0\n",
    "    \n",
    "    X_chain = onp.zeros((N, dimx))\n",
    "    \n",
    "    for n in range(N):\n",
    "        \n",
    "        x_proposed = x + stepsize*onp.random.normal(0,1,dimx)  ## same as ~N(x|x_n,sigma^2 I_dimx)\n",
    "        \n",
    "        # solve rans\n",
    "        logp_proposed = posterior.LogEvaluate(x_proposed)   # Target density\n",
    "\n",
    "        if onp.log(onp.random.uniform()) <= logp_proposed - logp:  #(as we took log of the acceptance ratio)\n",
    "            # accept\n",
    "            x=x_proposed\n",
    "            logp = logp_proposed\n",
    "            accepted += 1\n",
    "            \n",
    "        X_chain[n,:] = x\n",
    "        \n",
    "    print(\"Acceptance ratio: {}\".format(accepted / N))\n",
    "        \n",
    "    return X_chain\n",
    "        \n",
    "\n",
    "#mut_chain = random_walk_metropolis_hastings(5000, 0.05, onp.zeros(dim_mut))   # Samples of the posterior\n",
    "#mut_chain = random_walk_metropolis_hastings(5000, 0.05, mu_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Adjusted Langevin Dynamics (MALA)\n",
    "This is basically a discrete time Markov chain with a non-symmetric transition kernel:\n",
    "$$\n",
    "T(x,x') = \\mathcal{N}\\left(x'|x + \\Delta t\\nabla \\log h(x), 2\\Delta t\\right) \\propto \\exp\\left\\{-\\frac{\\parallel x+\\Delta t\\log h(x)-x'\\parallel_2^2}{4\\Delta t}\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mala(x0, log_h, n, dt, args=()): #def mala(x0, n, dt):    #def mala(x0, log_h, n, dt, args=()): ATUL\n",
    "    \"\"\"\n",
    "    Random walk metropolis.\n",
    "    \n",
    "    :param x0:     The initial point (numpy array).\n",
    "    :param log_h:  The logartihm of the function that is proportional to the density you want to sample from (function).\n",
    "                   Returns also the gradient.\n",
    "    :param n:      The maximum number of steps you want to take.\n",
    "    :param dt:     The time step you want to use.\n",
    "    :param args:   Any parameters to log_h\n",
    "    \n",
    "    :returns:  X, acceptance_rate\n",
    "    \"\"\"\n",
    "    x0 = onp.array(x0)\n",
    "    assert x0.ndim == 1\n",
    "    # Dimensionality of space\n",
    "    d = x0.shape[0]\n",
    "    # A place to store the samples\n",
    "    X = onp.ndarray((n + 1, d))\n",
    "    X[0, :] = x0\n",
    "    # Previous value of log(h(x))\n",
    "    log_h_p, grad_log_h_p = log_h(x0, *args)\n",
    "    #log_h_p=posterior.LogEvaluate(x0)  #Atul\n",
    "    #grad_log_h_p=posterior_grad(x0)    #Atul\n",
    "\n",
    "    # Keep track of how many samples are accepted\n",
    "    count_accepted = 0\n",
    "    # Start the simulation\n",
    "    for t in tqdm(range(1, n + 1)):\n",
    "        # Generation\n",
    "        x = X[t - 1, :] + dt * grad_log_h_p + onp.sqrt(2. * dt) * onp.random.randn(d)\n",
    "        # Calculation\n",
    "        log_h_c, grad_log_h_c = log_h(x, *args) # Current value of log(h(x))\n",
    "        #log_h_c=posterior.LogEvaluate(x)  #Atul, can save output of RANS here and use later for plots\n",
    "        #grad_log_h_c=posterior_grad(x)    #Atul\n",
    "        \n",
    "        log_alpha_1 = log_h_c - log_h_p\n",
    "        log_T_p_to_c = -onp.sum((x - X[t - 1, :] - dt * grad_log_h_p) ** 2 / (4. * dt))\n",
    "        log_T_c_to_p = -onp.sum((x + dt * grad_log_h_c - X[t - 1, :]) ** 2 / (4. * dt))\n",
    "        log_alpha_2 = log_T_c_to_p - log_T_p_to_c\n",
    "        log_alpha = log_alpha_1 + log_alpha_2\n",
    "        alpha = min(1, onp.exp(log_alpha))\n",
    "        \n",
    "        if t % 10 == 0:\n",
    "           xla._xla_callable.cache_clear()  # To empty the cache. was causing memory leak\n",
    "        # Accept/Reject\n",
    "        u = onp.random.rand()\n",
    "        if u <= alpha: # Accept\n",
    "            X[t, :] = x\n",
    "            log_h_p = log_h_c\n",
    "            grad_log_h_p = grad_log_h_c\n",
    "            count_accepted += 1\n",
    "        else:          # Reject\n",
    "            X[t, :] = X[t - 1, :]\n",
    "    # Empirical acceptance rate\n",
    "    acceptance_rate = count_accepted / (1. * n)\n",
    "    return X, acceptance_rate\n",
    "\n",
    "\n",
    "\n",
    "# Initialiazation:\n",
    "#x0 = onp.zeros(dim_mut)\n",
    "#x0=res.x\n",
    "# Parameters of the proposal:\n",
    "#dt = 0.0000001\n",
    "# Number of steps:\n",
    "#n = 40\n",
    "#X, acceptance_rate = mala(x0, n, dt)\n",
    "#X, acceptance_rate = mala(x0,log_h, n, dt,args=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximising posterior to select initial point (MAP)\n",
    "def m_log_h(x):\n",
    "    tmp1,tmp2=log_h(x)\n",
    "    return -tmp1,-tmp2\n",
    "\n",
    "#x0_BFGS=onp.zeros(mesh.y.size)\n",
    "x0_BFGS=mu_t[1:-1]\n",
    "res = scipy.optimize.minimize(m_log_h, x0_BFGS, jac=True, args=(),options={'disp': True})\n",
    "\n",
    "#res = scipy.optimize.minimize(log_h, mu_t,method='bfgs', jac=True,options={'disp': True})\n",
    "#res = scipy.optimize.minimize(log_h, mu_t, method='Powell', jac=True, args=(ssigma_prior, ssigma_likelihood), options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deterministic solution\n",
    "u_opt=solveRANS(res.x)\n",
    "plt.plot(u_opt, mesh.y,'*',label=\"$U_{opt}$\")\n",
    "plt.plot(u_DNS,mesh.y, 'r-', label='DNS')\n",
    "plt.xlabel('$U$'), plt.ylabel('$y$'), plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(res.x,mesh.y[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mu=res.inverhessian\n",
    "R=onp.linalg.cholesky(cov_mu)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val,grad_chk=log_h(res.x,10,ss)\n",
    "val2,grad_chk2=log_h(res.x+0.001*onp.ones(onp.size(res.x)),10,8)\n",
    "plt.plot(np.arange(np.size(res.x)),grad_chk,'b-',label=\"JAX\")\n",
    "plt.plot(np.arange(np.size(res.x)),grad_chk2,'r-',label=\"JAX2\")\n",
    "print('value=',val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling MALA sampler\n",
    "# Initialiazation:\n",
    "x0 = mu_t\n",
    "#x0=res.x\n",
    "# Parameters of the proposal:\n",
    "dt = 1.5e-10 ## Notice here step size is the varience so it will be sqrt. \n",
    "#dt=1e-08 ## check\n",
    "# Number of steps:\n",
    "n = 200\n",
    "#X, acceptance_rate = mala(x0, n, dt)\n",
    "X, acceptance_rate = mala(x0,log_h, n, dt,args=())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=1e-17\n",
    "n=100\n",
    "X_new,acceptance_rate=mala(X[-1,:],log_h, n, dt,args=(ssigma_prior,ssigma_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_rate\n",
    "#np.save('Samples'+date,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,75], label='$\\mu(75)$')\n",
    "#plt.plot(X[:,76], label='$\\mu(76)$')\n",
    "plt.xlabel('$Iterations/samples$'), plt.ylabel('$\\mu_t$'), plt.legend(loc=\"upper right\")\n",
    "#plt.savefig('Figures/parameter_evolution'+date+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred=onp.ndarray((X.shape[0],150))\n",
    "# posterior samples\n",
    "for n in range(X.shape[0]):\n",
    "    u_pred[n,:] = solveRANS(X[-n-1,:]) #+ ssigma_likelihood*onp.random.normal(0,1) # just added noise, can be ignored also       #u_pred= N(mean, ssigma); mean solveRANS(mu_smapleded)\n",
    "    \n",
    "    plt.plot(u_pred[n,:],mesh.y, 'k--', alpha=0.25)\n",
    "\n",
    "# reference\n",
    "u_RANS=solveRANS(mu_t_RANS)\n",
    "plt.plot(u_RANS, mesh.y,'b-',label=\"$U_{RANs}$\")\n",
    "plt.plot(u_DNS,mesh.y, 'r-', label='reference')\n",
    "plt.xlabel('$U$'), plt.ylabel('$y$'), plt.legend(loc=\"upper right\")\n",
    "#plt.savefig('Figures/DNSvsOpt_MultiPara_Bayesian_MALA'+date+'.png')\n",
    "#np.save('U_pred'+date,u_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred=onp.ndarray((X.shape[0],150))\n",
    "# posterior samples\n",
    "for n in range(X.shape[0]):\n",
    "    u_pred[n,:] = solveRANS(X[-n-1,:]) #+ ssigma_likelihood*onp.random.normal(0,1) # just added noise, can be ignored also       #u_pred= N(mean, ssigma); mean solveRANS(mu_smapleded)\n",
    "    \n",
    "    #plt.plot(u_pred[n,:],mesh.y, 'k--', alpha=0.25)\n",
    "\n",
    "# reference\n",
    "u_RANS=solveRANS(mu_t_RANS)\n",
    "\n",
    "U_mean_mv=np.mean(u_pred[:,:],axis=0)\n",
    "U_std_mv=np.std(u_pred[:,:],axis=0)\n",
    "plt.plot(U_mean_mv,mesh.y,label='$\\hat{U} \\pm \\sigma$')\n",
    "sd1_mv=U_mean_mv-2*U_std_mv\n",
    "sd2_mv=U_mean_mv+2*U_std_mv\n",
    "plt.plot(sd1_mv,mesh.y,linestyle='dashed',color='green')\n",
    "plt.plot(sd2_mv,mesh.y,linestyle='dashed',color='green')\n",
    "plt.plot(u_DNS,mesh.y, 'r-', label='DNS')\n",
    "plt.xlabel('$U$'), plt.ylabel('$y$'), plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for n in range(1,X.shape[0]):\n",
    "    if n%1==0:\n",
    "        #print(n)\n",
    "        diff=onp.linalg.norm(onp.mean(u_pred[:n,:],axis=0)-u_DNS)  \n",
    "        plt.semilogy(n,diff,'*')\n",
    "plt.xlabel('n(samples)')\n",
    "plt.ylabel('$||\\mathbb{E}(X)-\\mu||$')\n",
    "#plt.savefig('Figures/MeanError_MultiVar_MALA'+date+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0,70],X[0,71],'*')\n",
    "plt.plot(X[:,70],X[:,71])\n",
    "plt.plot(X[399,70],X[399,71],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X[:,70],bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(500):\n",
    "    plt.plot(X[-n-1,:]) #label=\"Optimised $\\mu_t (posterior)$\")\n",
    "\n",
    "plt.plot(mu_t,'r-', label=\" RANS $\\mu_t (prior)$\")\n",
    "plt.xlabel('$i$'),plt.ylabel('$\\mu_t[i]$'),plt.legend()\n",
    "plt.savefig('Figures/RANSmutVsmutOpt_Bayesian_MALA'+date+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing the samplers \n",
    "MCMC samplers (MH or MALA) on multivariate Gaussians i.e.:\n",
    "\n",
    "- assume some mean vector and covariance matrix for a target Gaussian\n",
    "\n",
    "- produce N samples using MCMC for this target Gaussian\n",
    "\n",
    "- estimate mean and covariance of the samples and plot the euclidean norm of their difference with the target mean and covariance respectively as a function of N\n",
    "\n",
    "- start in dimension 2 so you can plot the samples and then move to dimension 10 and dimension 100.\n",
    "\n",
    "- in dimension 2 increase the correlation in the target and see how this affects the performance of your samplers. (change the structur of cov matrix and make the parameters more realted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Target(object):\n",
    "    \"\" #Write Desciption here\n",
    "    def __init__(self, mean, ssigma, f = None):\n",
    "\n",
    "        self._mean = mean\n",
    "        self._ssigma = ssigma  # sigma squared, i.e. variance\n",
    "        \n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self._mean.size\n",
    "        \n",
    "    def LogEvaluate(self, x):\n",
    "        return ss.multivariate_normal(self._mean,self._ssigma).pdf(x)\n",
    "        #return -0.5*self.dim*onp.log(2*onp.pi) - 0.5*self.dim*self._ssigma - (1/self._ssigma)*onp.dot(x-self._mean, x-self._mean)\n",
    "    \n",
    "#Checking \n",
    "mean=onp.zeros(2)\n",
    "#cov=1\n",
    "cov=[[1, 0], [0, 1]]  # correlation is zero\n",
    "target_prob=Target(mean,cov)\n",
    "\n",
    "x_init=[4,4]\n",
    "y=target_prob.LogEvaluate(x_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(samples[:,0])\n",
    "x, y = onp.mgrid[-3:3:.01, -3:3:.01]\n",
    "pos = onp.empty(x.shape + (2,))\n",
    "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "yy=target_prob.LogEvaluate(pos)\n",
    "plt.axis('equal')\n",
    "plt.contourf(x, y, yy)\n",
    "#plt.plot(samples[:,0], samples[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_metropolis(N, stepsize, x0):\n",
    "    \n",
    "    x = x0  #Intial value for mut essentially/start with {0}\n",
    "    dimx = np.size(x0)\n",
    "    logp = target_prob.LogEvaluate(x0)\n",
    "    accepted = 0\n",
    "    \n",
    "    X_chain = onp.zeros((N, dimx))\n",
    "    \n",
    "    for n in tqdm(range(N)):\n",
    "        \n",
    "        x_proposed = x + stepsize*onp.random.normal(0,1,dimx)\n",
    "        \n",
    "        # solve rans\n",
    "        logp_proposed = target_prob.LogEvaluate(x_proposed)   # Target density\n",
    "\n",
    "        if onp.random.uniform() <= logp_proposed/logp:  #(as we took log of the acceptance ratio)\n",
    "            # accept\n",
    "            x=x_proposed\n",
    "            logp = logp_proposed\n",
    "            accepted += 1\n",
    "            \n",
    "        X_chain[n,:] = x\n",
    "        \n",
    "    print(\"Acceptance ratio: {}\".format(accepted / N))\n",
    "        \n",
    "    return X_chain\n",
    "        \n",
    "\n",
    "#mut_chain = random_walk_metropolis_hastings(5000, 0.05, onp.zeros(dim_mut))   # Samples of the posterior\n",
    "samples = random_walk_metropolis(50000, 1, x_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples)\n",
    "plt.xlabel('n(samples)')\n",
    "plt.figure()\n",
    "plt.plot(samples[:,0], samples[:,1])\n",
    "plt.xlabel('$X_1$'), plt.ylabel('$X_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,onp.size(samples[:,0])):\n",
    "    if n%100==0:\n",
    "        #print(n)\n",
    "        diff=onp.linalg.norm(onp.mean(samples[:n,:])-mean)   # np.cumsum is shorter \n",
    "        plt.plot(n,diff,'*')\n",
    "plt.xlabel('n(samples)')\n",
    "plt.ylabel('$||\\mathbb{E}(X)-\\mu||$')\n",
    "plt.figure()\n",
    "for n in range(1,onp.size(samples[:,0])):\n",
    "    if n%100==0:\n",
    "        #print(n)\n",
    "        diff=onp.linalg.norm(onp.cov(samples[:n,0],samples[:n,1])-cov)  # V[X]=E[X^2]-E[X]^2\n",
    "        plt.plot(n,diff,'*')\n",
    "plt.xlabel('n(samples)')\n",
    "plt.ylabel('$||\\mathbb{V}(X)-cov(X)||$')\n",
    "#Covar value should be close to zero as see from the circular scatter plot. Two parameteres are not correlated. "
   ]
  },
